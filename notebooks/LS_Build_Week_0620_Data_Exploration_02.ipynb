{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS Build Week 0620 Data Exploration 02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ipp_FbbUNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPtcRngq7Jpn",
        "colab_type": "text"
      },
      "source": [
        "## IMPORT STRAIN & SYMPTOM DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdcIgzvWg35V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the symptoms_updated.xls file\n",
        "df_data = pd.read_excel(\"https://dsfiles.dananderson.dev/files/symptoms_updated.xls\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJQUzIdQqeLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ef752046-bfa9-4fef-d6e1-2264bbad32f2"
      },
      "source": [
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Strain</th>\n",
              "      <th>Type</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Effects</th>\n",
              "      <th>Flavor</th>\n",
              "      <th>symptoms_diseases</th>\n",
              "      <th>Description</th>\n",
              "      <th>text_all</th>\n",
              "      <th>Effects_and_Flavor</th>\n",
              "      <th>tokens</th>\n",
              "      <th>description_formatted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>100-Og</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Creative, Energetic, Tingly, Euphoric, Relaxed</td>\n",
              "      <td>Earthy, Sweet, Citrus</td>\n",
              "      <td>ms, pain, pain, spasticity,</td>\n",
              "      <td>$100 OG is a 50/50 hybrid strain that packs a ...</td>\n",
              "      <td>Creative  Energetic  Tingly  Euphoric  Relaxed...</td>\n",
              "      <td>Creative, Energetic, Tingly, Euphoric, Relaxed...</td>\n",
              "      <td>['creative', 'energetic', 'tingly', 'euphoric'...</td>\n",
              "      <td>$100 og is a 50/50 hybrid strain that packs a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>98-White-Widow</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.7</td>\n",
              "      <td>Relaxed, Aroused, Creative, Happy, Energetic</td>\n",
              "      <td>Flowery, Violet, Diesel</td>\n",
              "      <td>spasticity,</td>\n",
              "      <td>The ‚Äò98 Aloha White Widow is an especially p...</td>\n",
              "      <td>Relaxed  Aroused  Creative  Happy  Energetic  ...</td>\n",
              "      <td>Relaxed, Aroused, Creative, Happy, Energetic, ...</td>\n",
              "      <td>['relaxed', 'aroused', 'creative', 'happy', 'e...</td>\n",
              "      <td>the ‚Äò98 aloha white widow is an especially p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1024</td>\n",
              "      <td>sativa</td>\n",
              "      <td>4.4</td>\n",
              "      <td>Uplifted, Happy, Relaxed, Energetic, Creative</td>\n",
              "      <td>Spicy/Herbal, Sage, Woody</td>\n",
              "      <td>pain, pain, spasticity,</td>\n",
              "      <td>1024 is a sativa-dominant hybrid bred in Spain...</td>\n",
              "      <td>Uplifted  Happy  Relaxed  Energetic  Creative ...</td>\n",
              "      <td>Uplifted, Happy, Relaxed, Energetic, Creative,...</td>\n",
              "      <td>['uplifted', 'happy', 'relaxed', 'energetic', ...</td>\n",
              "      <td>1024 is a sativa-dominant hybrid bred in spain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>13-Dawgs</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.2</td>\n",
              "      <td>Tingly, Creative, Hungry, Relaxed, Uplifted</td>\n",
              "      <td>Apricot, Citrus, Grapefruit</td>\n",
              "      <td>appetite, appetite, depression, spasticity,</td>\n",
              "      <td>13 Dawgs is a hybrid of G13 and Chemdawg genet...</td>\n",
              "      <td>Tingly  Creative  Hungry  Relaxed  Uplifted  A...</td>\n",
              "      <td>Tingly, Creative, Hungry, Relaxed, Uplifted, A...</td>\n",
              "      <td>['tingly', 'creative', 'hungry', 'relaxed', 'u...</td>\n",
              "      <td>13 dawgs is a hybrid of g13 and chemdawg genet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24K-Gold</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>4.6</td>\n",
              "      <td>Happy, Relaxed, Euphoric, Uplifted, Talkative</td>\n",
              "      <td>Citrus, Earthy, Orange</td>\n",
              "      <td>spasticity,</td>\n",
              "      <td>Also known as Kosher Tangie  24k Gold is a 60%...</td>\n",
              "      <td>Happy  Relaxed  Euphoric  Uplifted  Talkative ...</td>\n",
              "      <td>Happy, Relaxed, Euphoric, Uplifted, Talkative,...</td>\n",
              "      <td>['happy', 'relaxed', 'euphoric', 'uplifted', '...</td>\n",
              "      <td>also known as kosher tangie  24k gold is a 60%...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                              description_formatted\n",
              "0      0  ...  $100 og is a 50/50 hybrid strain that packs a ...\n",
              "1      1  ...  the ‚Äò98 aloha white widow is an especially p...\n",
              "2      2  ...  1024 is a sativa-dominant hybrid bred in spain...\n",
              "3      3  ...  13 dawgs is a hybrid of g13 and chemdawg genet...\n",
              "4      4  ...  also known as kosher tangie  24k gold is a 60%...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJSp0Wx77b5m",
        "colab_type": "text"
      },
      "source": [
        "## SPLIT DESCRIPTIONS OF EFFECTS, FLAVORS, AND SYMPTOMS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MyuT-_phUGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'split2list' splits a comma delimited string and returns a list of lower case tokens\n",
        "def split2list(val):\n",
        "  ret_list = []\n",
        "\n",
        "  # Is the passed value Nan?\n",
        "  if pd.isna(val):\n",
        "    return ['none']\n",
        "\n",
        "  # Is the value an empty string?\n",
        "  if val == \"\":\n",
        "    return ['none']\n",
        "\n",
        "  # Lower case the input value\n",
        "  tmp_lower = val.lower()\n",
        "\n",
        "  # Is the value \"none\"?\n",
        "  if tmp_lower == \"none\":\n",
        "    return ['none']\n",
        "\n",
        "  # Split the string value into tokens delimited by commas\n",
        "  tmp_list = tmp_lower.split(',')\n",
        "\n",
        "  # Is tmp_list empty?\n",
        "  if len(tmp_list) == 0:\n",
        "    return ['none']\n",
        "\n",
        "  # Iterate through the temp list and trim values\n",
        "  for elm in tmp_list:\n",
        "    # If the list element is all spaces then skip\n",
        "    if elm.strip() == \"\":\n",
        "      continue\n",
        "\n",
        "    # Otherwise strip the string of leading and trailing spaces and add to the\n",
        "    #  return list\n",
        "    ret_list.append(elm.strip())\n",
        "\n",
        "  # Return the list\n",
        "  return ret_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhtgwDPyqStY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a working copy of the initial dataframe\n",
        "df_data_upd = df_data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3KqCDVVqZBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataframe columns which consist of lists of tokens for Effects, Flavors, and Symptoms respectively\n",
        "df_data_upd[\"Effects_list\"]           = df_data_upd[\"Effects\"].apply(split2list)\n",
        "df_data_upd[\"Flavor_list\"]            = df_data_upd[\"Flavor\"].apply(split2list)\n",
        "df_data_upd[\"symptoms_diseases_list\"] = df_data_upd[\"symptoms_diseases\"].apply(split2list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVuqm4rHq43E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample the 'Effects_list' column\n",
        "df_data_upd[\"Effects_list\"].sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgwJFnNFuPQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample the 'Flavor_list' column\n",
        "df_data_upd[\"Flavor_list\"].sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkB4dhU7uVZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample the 'symptoms_diseases_list' column\n",
        "df_data_upd[\"symptoms_diseases_list\"].sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVeJzTpzwUTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "map_effects = {}\n",
        "map_flavors = {}\n",
        "map_symptoms = {}\n",
        "\n",
        "# gen_unique_values takes an inbound list of strings and adds them as keys to a map\n",
        "def gen_unique_values(lst, mp):\n",
        "  # Iterate through the list\n",
        "  for elm in lst:\n",
        "    # Is elm an empty string? Error condition\n",
        "    if elm == \"\":\n",
        "      print(\"error - encountered an empty string\")\n",
        "      return \n",
        "\n",
        "    mp[elm] = 0\n",
        "    return \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcscgD1Ayayq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate maps that contain unique Effects, Flavors, and Symtoms tokens\n",
        "df_data_upd[\"Effects_list\"].apply(gen_unique_values, mp=map_effects)\n",
        "df_data_upd[\"Flavor_list\"].apply(gen_unique_values, mp=map_flavors)\n",
        "df_data_upd[\"symptoms_diseases_list\"].apply(gen_unique_values, mp=map_symptoms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEaZW2ye7nMs",
        "colab_type": "text"
      },
      "source": [
        "## CLEAN STRAIN DESCRIPTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLVbqO82RJGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Steps to Clean the Strain Descriptions\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Regular expression used to remove non-standard characters\n",
        "rgxNotStdChars = re.compile(r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]')\n",
        "rgxMultWhtSpce = re.compile(r'\\s{2,}')\n",
        "\n",
        "# 'retain_std_chars' takes a string and returns that string with non-standard\n",
        "#    characters removed\n",
        "def retain_std_chars(val):\n",
        "  # Is the passed value NaN?\n",
        "  if pd.isna(val):\n",
        "    return 'none'\n",
        "\n",
        "  # Is the passed not a string?\n",
        "  if type(val) != str:\n",
        "    return 'none'\n",
        "\n",
        "  # Is the value an empty string?\n",
        "  if val == \"\":\n",
        "    return 'none'\n",
        "\n",
        "  # Lower case the input value\n",
        "  tmp_lower = val.lower()\n",
        "\n",
        "  # Is the value \"none\"?\n",
        "  if tmp_lower == \"none\":\n",
        "    return 'none'\n",
        "\n",
        "  # Remove non-standard characters\n",
        "  tmp_std = re.sub(rgxNotStdChars, \"\", tmp_lower)\n",
        "\n",
        "  # Convert multiple whitespace characters to one whitespace character\n",
        "  tmp_wht = re.sub(rgxMultWhtSpce, \"\", tmp_std)\n",
        "\n",
        "  # Strip leading and trailing whitespace\n",
        "  tmp_rtn = tmp_wht.strip()\n",
        "  \n",
        "  return tmp_rtn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWeCkzyVavF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data_upd['Description_cleaned'] = df_data_upd['Description'].apply(retain_std_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNy6SRUc708i",
        "colab_type": "text"
      },
      "source": [
        "## GENERATE WORK 'TOKENS' FOR THE STRAIN DESCRIPTIONS & CHARACTERISTICS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4YnAdE3YqS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the spacy library to generate strain description tokens\n",
        "import spacy\n",
        "\n",
        "# Instantiate a spacy object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# tnkize_text takes a string and returns a list of tokens generated via the spacy library\n",
        "def tnkize_text(val):\n",
        "  tmp_list = []\n",
        "  tmp_doc = nlp(val)\n",
        "\n",
        "  # Iterate through the text's tokenized objects\n",
        "  for tkn in tmp_doc:\n",
        "    tmp_list.append(tkn.text)\n",
        "\n",
        "  return tmp_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isiK7EYZiW3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a list of description tokens\n",
        "df_data_upd['Description_tokens'] =  df_data_upd['Description_cleaned'].apply(tnkize_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn7Eze1YjcqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "8715c4c0-f216-4cef-e9a1-14e0383571f6"
      },
      "source": [
        "df_data_upd['Description_tokens'].sample(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1407    [originating, in, amsterdam, and, currently, b...\n",
              "315     [blue, rhino, is, a, potent, cross, of, bluebe...\n",
              "8       [3d, cbd, from, snoop, doggs, branded, line, o...\n",
              "1498    [og, sharka, rare, strain, found, primarily, i...\n",
              "40      [this, popular, classic, strain, was, original...\n",
              "132     [ash, is, an, indicadominanthybrid, cross, bet...\n",
              "356     [bluniversealso, called, blue, universeis, a, ...\n",
              "1536    [orange, skunk, is, a, clearheaded, hybrid, cr...\n",
              "2119    [tardisor, the, tardisis, a, sativadominant, s...\n",
              "1176    [khola, is, a, sociable, cross, between, brazi...\n",
              "2001    [strawberry, blondie, by, los, angeles, kush, ...\n",
              "661     [diamond, valley, kush, is, an, indicadominant...\n",
              "597     [critical, 47, is, hybrid, in, genetics, and, ...\n",
              "444     [cannatsu, is, a, hybrid, cannabis, strain, th...\n",
              "1769    [red, widow, is, a, hybrid, cross, of, red, dr...\n",
              "1251    [lem, chem, is, a, potent, hybrid, that, is, b...\n",
              "1859                                               [none]\n",
              "1046    [holland, 's, hope, was, one, of, the, first, ...\n",
              "1402    [mint, chocolate, chip, is, a, rare, cross, of...\n",
              "2225    [like, the, name, suggestsvelvet, bud, will, p...\n",
              "Name: Description_tokens, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z4C03ucjns7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gen_all_tokens creates a column consisting of description, effects, \n",
        "#    flavors, and symptoms tokens (\"ALL_TOKENTS\")\n",
        "def gen_all_tokens(DF):\n",
        "  DF_WRK = DF.copy()\n",
        "\n",
        "  DF_WRK['ALL_TOKENS'] = DF_WRK['Description_tokens'] \\\n",
        "    + DF_WRK['Effects_list'] \\\n",
        "    + DF_WRK['Flavor_list'] \\\n",
        "    + DF_WRK['symptoms_diseases_list']\n",
        "\n",
        "  return DF_WRK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_a-5y1Fny5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a column ('ALL_TOKENS') of strain tokens that\n",
        "#   consist of the description, effects, flavors, and symptom tokens\n",
        "df_data_upd = gen_all_tokens(df_data_upd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xosDbbih7_pu",
        "colab_type": "text"
      },
      "source": [
        "## VECTORIZE EACH STRAIN'S DESCRIPTION & CHARACTERISTICS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eRq-GSD1BAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use TFIDF and vectorize the strain tokens ('ALL_TOKENS')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def dummy_fun(doc):\n",
        "    return doc\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    analyzer='word',\n",
        "    stop_words = 'english',\n",
        "    tokenizer=dummy_fun,\n",
        "    preprocessor=dummy_fun,\n",
        "    token_pattern=None) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTsyGYIO2SxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "964f4ed4-4af7-4f4c-c3ee-53f47b716821"
      },
      "source": [
        "# Create a vocabulary and tf-idf score per document\n",
        "dtm = tfidf.fit_transform(df_data_upd['ALL_TOKENS'])\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "print(dtm.shape)\n",
        "dtm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2350, 16412)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>!</th>\n",
              "      <th>'</th>\n",
              "      <th>'d</th>\n",
              "      <th>'s</th>\n",
              "      <th>.</th>\n",
              "      <th>...</th>\n",
              "      <th>/</th>\n",
              "      <th>0.14the</th>\n",
              "      <th>0.18</th>\n",
              "      <th>0.23</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.36</th>\n",
              "      <th>0.38</th>\n",
              "      <th>0.47</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.5cherry</th>\n",
              "      <th>0.86.with</th>\n",
              "      <th>00</th>\n",
              "      <th>09</th>\n",
              "      <th>1</th>\n",
              "      <th>1.07</th>\n",
              "      <th>1.1neville</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.3</th>\n",
              "      <th>1.4the</th>\n",
              "      <th>1.the</th>\n",
              "      <th>1/4</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1011</th>\n",
              "      <th>1012</th>\n",
              "      <th>1013</th>\n",
              "      <th>1015</th>\n",
              "      <th>1024</th>\n",
              "      <th>10as</th>\n",
              "      <th>10dynasty</th>\n",
              "      <th>10jenni</th>\n",
              "      <th>10of</th>\n",
              "      <th>10th</th>\n",
              "      <th>10week</th>\n",
              "      <th>...</th>\n",
              "      <th>ythe</th>\n",
              "      <th>yum</th>\n",
              "      <th>yumboldt</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yunnan</th>\n",
              "      <th>yunnanaceseeds</th>\n",
              "      <th>yunnanorient</th>\n",
              "      <th>yunnans</th>\n",
              "      <th>zacatecascolombian</th>\n",
              "      <th>zamal</th>\n",
              "      <th>zamaldelica</th>\n",
              "      <th>zambeza</th>\n",
              "      <th>zappas</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealandand</th>\n",
              "      <th>zealandmt</th>\n",
              "      <th>zealands</th>\n",
              "      <th>zealously</th>\n",
              "      <th>zellys</th>\n",
              "      <th>zen</th>\n",
              "      <th>zens</th>\n",
              "      <th>zero</th>\n",
              "      <th>zest</th>\n",
              "      <th>zestful</th>\n",
              "      <th>zesty</th>\n",
              "      <th>zestycitrusyand</th>\n",
              "      <th>zestyfloral</th>\n",
              "      <th>zeta</th>\n",
              "      <th>zeus</th>\n",
              "      <th>zingerslemon</th>\n",
              "      <th>zion</th>\n",
              "      <th>zipping</th>\n",
              "      <th>zkittlez</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zombiewith</th>\n",
              "      <th>zone</th>\n",
              "      <th>zonethe</th>\n",
              "      <th>zoning</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.123948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.207842</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.101194</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083726</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.221596</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.097243</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.130083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.071542</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 16412 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          !    '   'd   's         .  ...  zone  zonethe  zoning  zoom   zs\n",
              "0  0.000000  0.0  0.0  0.0  0.123948  ...   0.0      0.0     0.0   0.0  0.0\n",
              "1  0.000000  0.0  0.0  0.0  0.101194  ...   0.0      0.0     0.0   0.0  0.0\n",
              "2  0.000000  0.0  0.0  0.0  0.083726  ...   0.0      0.0     0.0   0.0  0.0\n",
              "3  0.000000  0.0  0.0  0.0  0.097243  ...   0.0      0.0     0.0   0.0  0.0\n",
              "4  0.130083  0.0  0.0  0.0  0.071542  ...   0.0      0.0     0.0   0.0  0.0\n",
              "\n",
              "[5 rows x 16412 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzSE2ixR8SUZ",
        "colab_type": "text"
      },
      "source": [
        "## CONSTRUCT A NEAREST NEIGHBORS MODEL TO GENERATE RECOMMENDATIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIB5Jneo3WEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e5a18261-fd49-45cc-9d31-f4c56052d6e1"
      },
      "source": [
        "# Define a Nearest Neighbors model on which to compare incoming text\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Fit on the nearest neighbors model TF-IDF feature matrix created above \n",
        "nn = NearestNeighbors(n_neighbors=8, algorithm='kd_tree')\n",
        "nn.fit(dtm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=8, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuN_1Y8x5YWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2d0ad774-79b6-4d88-dde4-23f36676fa16"
      },
      "source": [
        "nn.kneighbors([dtm.iloc[10].values])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.        , 1.06383587, 1.18811097, 1.26611709, 1.27393395,\n",
              "         1.29394996, 1.29730651, 1.29739092]]),\n",
              " array([[  10, 1929,  741,  649, 1372,  543, 1938, 1589]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcB7YaLc9ETa",
        "colab_type": "text"
      },
      "source": [
        "## GENERATE A SAMPLE RECOMMENDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USnYnpAH5zWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bcb75243-df32-4c21-be24-7b19b9b3045f"
      },
      "source": [
        "# Score a new document and return it's nearest neighbors\n",
        "new_doc_score = tfidf.transform([\"I want to feel super relaxed, yet energetic and creative\"])\n",
        "\n",
        "# Execute the nearest neighbors model using the newly scored document\n",
        "nn.kneighbors(new_doc_score.todense())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.2672429 , 1.30677659, 1.30944854, 1.35269312, 1.35478938,\n",
              "         1.36501368, 1.36675039, 1.37157906]]),\n",
              " array([[1178, 1817,   84, 1140,  103,  628, 1354, 2334]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szuxFqyZ6xw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8f523034-d53c-44ee-a164-db4931d1de4e"
      },
      "source": [
        "df_data_upd.iloc[84]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                                                                    84\n",
              "Strain                                                     Alien-Technology\n",
              "Type                                                                 indica\n",
              "Rating                                                                  4.5\n",
              "Effects                         Happy, Relaxed, Uplifted, Euphoric, Focused\n",
              "Flavor                                          Earthy, Spicy/Herbal, Woody\n",
              "symptoms_diseases                                              spasticity, \n",
              "Description               Very little is known about Alien Technology ot...\n",
              "text_all                  Happy  Relaxed  Uplifted  Euphoric  Focused  E...\n",
              "Effects_and_Flavor        Happy, Relaxed, Uplifted, Euphoric, Focused, E...\n",
              "tokens                    ['happy', 'relaxed', 'uplifted', 'euphoric', '...\n",
              "description_formatted     very little is known about alien technology ot...\n",
              "Effects_list                  [happy, relaxed, uplifted, euphoric, focused]\n",
              "Flavor_list                                   [earthy, spicy/herbal, woody]\n",
              "symptoms_diseases_list                                         [spasticity]\n",
              "Description_cleaned       very little is known about alien technology ot...\n",
              "Description_tokens        [very, little, is, known, about, alien, techno...\n",
              "ALL_TOKENS                [very, little, is, known, about, alien, techno...\n",
              "Name: 84, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}